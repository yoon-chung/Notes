# PyTorch 텐서 조작 (Tensor Manipulation)

## 목차
1. [텐서 이해하기](#1-텐서-이해하기)
2. [텐서의 모양 바꾸기](#2-텐서의-모양-바꾸기)
3. [텐서 합치기와 나누기](#3-텐서-합치기와-나누기)

---

## 1. 텐서 이해하기

### 1-1. 텐서 생성

#### 무작위 값 생성

| 함수 | 설명 | 예시 |
|------|------|------|
| `torch.rand(n, m)` | 0~1 균등분포 | `torch.rand(2, 3)` |
| `torch.randn(n, m)` | 평균 0, 표준편차 1 정규분포 | `torch.randn(2, 3)` |
| `torch.randint(low, high, size)` | 정수 범위 내 무작위 (high 미포함) | `torch.randint(1, 10, (5, 5))` |

#### 특정 값으로 생성

| 함수 | 설명 | 예시 |
|------|------|------|
| `torch.zeros(size)` | 모든 요소 0 | `torch.zeros(3, 3)` |
| `torch.ones(size)` | 모든 요소 1 | `torch.ones(2, 2, 2)` |
| `torch.full(size, value)` | 모든 요소 지정값 | `torch.full((2, 3), 5)` |
| `torch.eye(n)` | 단위 행렬 | `torch.eye(3)` |

#### 데이터 → 텐서 변환

| 함수 | 설명 | 특징 |
|------|------|------|
| `torch.tensor(data)` | list, tuple, numpy → 텐서 | 원본 dtype 유지 |
| `torch.Tensor(data)` | 텐서 변환 | **float32로 변환** |
| `torch.from_numpy(arr)` | numpy array → 텐서 | 메모리 공유 |
| `torch.as_tensor(data)` | 텐서 변환 | **메모리 공유** (원본 변경 시 텐서도 변경) |

```python
# tensor vs as_tensor 차이
data = np.array([1, 2, 3])
t1 = torch.tensor(data)    # 복사 (원본 변경 영향 X)
t2 = torch.as_tensor(data) # 공유 (원본 변경 영향 O)
```

### 1-2. 인덱싱 (Indexing)

#### 기본 인덱싱
```python
t = torch.tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])
t[0]    # 첫번째 → tensor(0)
t[-1]   # 마지막 → tensor(9)
t[2:5]  # 슬라이싱 → tensor([2, 3, 4])
```

#### 고급 인덱싱

| 함수 | 설명 | 예시 |
|------|------|------|
| `index_select(t, dim, index)` | 특정 차원에서 인덱스 선택 | `torch.index_select(t, dim=1, index=torch.tensor([0, 2]))` |
| `t[mask]` | 조건 마스킹 | `t[t >= 5]` |
| `masked_select(t, mask)` | 마스크 선택 (1차원 반환) | `torch.masked_select(t, t >= 5)` |
| `take(t, index)` | 1차원 기준 인덱스 | `torch.take(t, torch.tensor([0, 15]))` |
| `gather(t, dim, index)` | 차원별 인덱스 재구성 | `torch.gather(t, dim=1, index=idx)` |

---

## 2. 텐서의 모양 바꾸기

### 2-1. Shape 변경

#### 크기 확인
```python
t = torch.randn(2, 3, 5)
t.size()   # torch.Size([2, 3, 5])
t.shape    # torch.Size([2, 3, 5])
```

#### reshape vs view

| 함수 | 설명 | contiguous 필요 |
|------|------|----------------|
| `reshape(size)` | 모양 변경 | ❌ (자동 처리) |
| `view(size)` | 모양 변경 | ✅ (필수) |

```python
t = torch.randn(2, 3, 5)
t.reshape(5, 6)    # (2,3,5) → (5,6)
t.reshape(3, -1)   # -1은 자동 계산 → (3, 10)
```

> **contiguous란?** 메모리 상 연속적 배치. `transpose` 후에는 non-contiguous 상태가 됨.

```python
t_transposed = t.transpose(0, 1)
t_transposed.is_contiguous()  # False
t_transposed.view(-1)         # ❌ 에러
t_transposed.reshape(-1)      # ✅ 동작
```

#### transpose vs permute

| 함수 | 설명 | 인자 |
|------|------|------|
| `transpose(dim0, dim1)` | 두 차원만 교환 | 2개 |
| `permute(dims)` | 모든 차원 재배열 | 전체 차원 수 |

```python
t = torch.randn(2, 3, 5)
t.transpose(1, 2)      # (2,3,5) → (2,5,3)
t.permute(0, 2, 1)     # (2,3,5) → (2,5,3)
```

### 2-2. 차원 추가/제거

| 함수 | 설명 | 예시 |
|------|------|------|
| `unsqueeze(dim)` | 크기 1인 차원 추가 | `(5,2)` → `unsqueeze(0)` → `(1,5,2)` |
| `squeeze()` | 크기 1인 차원 제거 | `(1,5,2)` → `squeeze()` → `(5,2)` |
| `squeeze(dim)` | 특정 차원만 제거 | `(2,1,2,1,2)` → `squeeze(1)` → `(2,2,1,2)` |

### 2-3. 텐서 확장

| 함수 | 설명 | 메모리 공유 |
|------|------|-----------|
| `expand(size)` | 크기 1인 차원만 확장 가능 | ✅ 공유 |
| `repeat(repeats)` | 텐서 자체를 반복 | ❌ 복사 |

```python
t = torch.tensor([1, 2, 3, 4])  # (4,)

t.expand(3, 4)   # (4,) → (3,4) 값 반복
# [[1,2,3,4], [1,2,3,4], [1,2,3,4]]

t.repeat(3, 2)   # (4,) → (3,8) 텐서 반복
# [[1,2,3,4,1,2,3,4], [1,2,3,4,1,2,3,4], [1,2,3,4,1,2,3,4]]
```

### 2-4. 평탄화

| 함수 | 설명 | start_dim 지원 |
|------|------|---------------|
| `flatten()` | 다차원 → 1차원 | ✅ |
| `ravel()` | 다차원 → 1차원 | ❌ |

```python
t = torch.randn(2, 5, 2)
t.flatten()              # (2,5,2) → (20,)
t.flatten(start_dim=1)   # (2,5,2) → (2,10)
```

---

## 3. 텐서 합치기와 나누기

### 3-1. 텐서 합치기

| 함수 | 설명 | 조건 |
|------|------|------|
| `cat(tensors, dim)` | 기존 차원을 따라 연결 | 지정 차원 외 크기 동일 |
| `stack(tensors, dim)` | 새로운 차원 추가하며 쌓기 | 모든 텐서 크기 동일 |

```python
a = torch.randn(2, 3)
b = torch.randn(5, 3)

torch.cat((a, b), dim=0)   # (2,3) + (5,3) → (7,3)
```

```python
a = torch.randn(3, 2)
b = torch.randn(3, 2)

torch.stack([a, b], dim=0)  # (3,2), (3,2) → (2,3,2)
```

### 3-2. 텐서 나누기

| 함수 | 설명 | 인자 |
|------|------|------|
| `chunk(t, chunks, dim)` | **개수**로 나누기 | chunks: 텐서 개수 |
| `split(t, split_size, dim)` | **크기**로 나누기 | split_size: int 또는 list |

```python
t = torch.randn(6, 4)

# chunk: 3개로 나누기
torch.chunk(t, chunks=3, dim=0)  # (6,4) → (2,4), (2,4), (2,4)

# split: 크기 2로 나누기
torch.split(t, split_size_or_sections=2, dim=0)  # (6,4) → (2,4), (2,4), (2,4)

# split: 각각 다른 크기로 나누기
torch.split(t, split_size_or_sections=[2, 4], dim=0)  # (6,4) → (2,4), (4,4)
```

---

## 핵심 비교 정리

### reshape vs view vs unsqueeze

| 함수 | contiguous 필요 | 차원 변경 자유도 |
|------|----------------|-----------------|
| `view` | ✅ | 자유 |
| `reshape` | ❌ | 자유 |
| `unsqueeze` | ❌ | 크기 1인 차원만 추가 |

### expand vs repeat

| 함수 | 메모리 | 확장 조건 |
|------|--------|----------|
| `expand` | 공유 | 크기 1인 차원만 |
| `repeat` | 복사 | 제한 없음 |

### cat vs stack

| 함수 | 차원 변화 | 크기 조건 |
|------|----------|----------|
| `cat` | 유지 | 결합 차원 외 동일 |
| `stack` | +1 증가 | 모든 차원 동일 |

### chunk vs split

| 함수 | 나누는 기준 |
|------|-----------|
| `chunk` | 텐서 **개수** |
| `split` | 텐서 **크기** |

---

## Reference
- [PyTorch 공식 문서](https://pytorch.org/docs/stable/index.html)
- [view, transpose, reshape 비교](https://inmoonlight.github.io/2021/03/03/PyTorch-view-transpose-reshape/)
