# PyTorch ë””ë²„ê¹… - ìì£¼ ë°œìƒí•˜ëŠ” ì—ëŸ¬ì™€ í•´ê²°ë²•

## ëª©ì°¨
1. [Custom Dataset êµ¬í˜„ ì‹œ ì—ëŸ¬](#1-custom-dataset-êµ¬í˜„-ì‹œ-ì—ëŸ¬)
2. [Custom Model êµ¬í˜„ ì‹œ ì—ëŸ¬](#2-custom-model-êµ¬í˜„-ì‹œ-ì—ëŸ¬)
3. [í•™ìŠµ ë° í‰ê°€ ì‹œ ì—ëŸ¬](#3-í•™ìŠµ-ë°-í‰ê°€-ì‹œ-ì—ëŸ¬)
4. [í”í•œ ì‹¤ìˆ˜ ì‚¬ë¡€](#4-í”í•œ-ì‹¤ìˆ˜-ì‚¬ë¡€)

---

## ë””ë²„ê¹… ê¸°ë³¸ ì›ì¹™

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ì—ëŸ¬ í•´ê²° í”„ë¡œì„¸ìŠ¤                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚   1ï¸âƒ£ ì—ëŸ¬ ë©”ì‹œì§€ ì½ê¸°                                           â”‚
â”‚      â””â”€ Python/PyTorchëŠ” ì–´ë””ì„œ, ì™œ ì—ëŸ¬ê°€ ë°œìƒí–ˆëŠ”ì§€ ì•Œë ¤ì¤Œ     â”‚
â”‚                                                                 â”‚
â”‚   2ï¸âƒ£ í‚¤ì›Œë“œ ê¸°ë°˜ êµ¬ê¸€ ê²€ìƒ‰                                      â”‚
â”‚      â””â”€ ëŒ€ë¶€ë¶„ì˜ ì—ëŸ¬ëŠ” ë‹¤ë¥¸ ê°œë°œìë“¤ì´ ì´ë¯¸ í•´ê²°ì±…ì„ ê³µìœ í•¨     â”‚
â”‚                                                                 â”‚
â”‚   3ï¸âƒ£ ì½”ë“œ ë¹„êµ ë° ì´í•´                                          â”‚
â”‚      â””â”€ í•´ê²°ì±…ì„ ì°¾ì€ í›„, ìì‹ ì˜ ì½”ë“œì™€ ë¹„êµí•˜ë©° ì›ì¸ íŒŒì•…       â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 1. Custom Dataset êµ¬í˜„ ì‹œ ì—ëŸ¬

### 1-1. `__len__` ë©”ì„œë“œ ì—ëŸ¬

#### ë¬¸ì œ ìƒí™©

```python
class CustomDataset(Dataset):
    def __init__(self, data):
        self.data = data
    
    def __len__(self):
        return 1000  # âŒ í•˜ë“œì½”ë”©ëœ ê°’
    
    def __getitem__(self, idx):
        return self.data[idx]
```

#### ë°œìƒí•˜ëŠ” ë¬¸ì œ

| ìƒí™© | ê²°ê³¼ |
|------|------|
| `__len__` < ì‹¤ì œ ë°ì´í„° ìˆ˜ | ì¼ë¶€ ë°ì´í„°ë§Œ ì‚¬ìš©ë¨ |
| `__len__` > ì‹¤ì œ ë°ì´í„° ìˆ˜ | **IndexError** ë°œìƒ |

#### ì˜¬ë°”ë¥¸ ì½”ë“œ

```python
class CustomDataset(Dataset):
    def __init__(self, data):
        self.data = data
    
    def __len__(self):
        return len(self.data)  # âœ… ì‹¤ì œ ë°ì´í„° ìˆ˜ ë°˜í™˜
    
    def __getitem__(self, idx):
        return self.data[idx]
```

> ğŸ“š ê²€ìƒ‰ í‚¤ì›Œë“œ: `pytorch custom dataset IndexError`

---

### 1-2. `__getitem__` ë©”ì„œë“œ ì—ëŸ¬

#### ë¬¸ì œ ìƒí™©

```python
def __getitem__(self, idx):
    return self.X[idx + 1], self.label[idx + 1]  # âŒ ì˜ëª»ëœ ì¸ë±ìŠ¤ ì ‘ê·¼
```

#### ì˜¬ë°”ë¥¸ ì½”ë“œ

```python
def __getitem__(self, idx):
    return self.X[idx], self.label[idx]  # âœ… ì˜¬ë°”ë¥¸ ì¸ë±ìŠ¤ ì ‘ê·¼
```

---

### 1-3. ë°ì´í„° íƒ€ì… ì—ëŸ¬ (RuntimeError)

#### ë¬¸ì œ ìƒí™©

`nn.Embedding`ì€ **Long íƒ€ì…** í…ì„œë¥¼ ìš”êµ¬í•˜ëŠ”ë°, Float íƒ€ì…ì„ ì…ë ¥í•œ ê²½ìš°

```python
# âŒ Float íƒ€ì…ìœ¼ë¡œ ì €ì¥
self.X = torch.tensor(self.seq[:, :-1]).float()

# Embedding layer í†µê³¼ ì‹œ ì—ëŸ¬ ë°œìƒ
# RuntimeError: Expected tensor for argument #1 'indices' to have 
# scalar type Long; but got torch.FloatTensor instead
```

#### ì˜¬ë°”ë¥¸ ì½”ë“œ

```python
# âœ… Long íƒ€ì…ìœ¼ë¡œ ì €ì¥
self.X = torch.tensor(self.seq[:, :-1]).long()

# ë˜ëŠ” __getitem__ì—ì„œ ë³€í™˜
def __getitem__(self, idx):
    return self.X[idx].long(), self.label[idx].long()
```

#### ë ˆì´ì–´ë³„ ìš”êµ¬ ë°ì´í„° íƒ€ì…

| ë ˆì´ì–´ | ìš”êµ¬ íƒ€ì… |
|--------|----------|
| `nn.Embedding` | **Long** (ì •ìˆ˜) |
| `nn.Linear` | Float |
| `nn.Conv2d` | Float |
| `nn.CrossEntropyLoss` | labels: **Long** |

> ğŸ“š ê²€ìƒ‰ í‚¤ì›Œë“œ: `nn.Embedding RuntimeError`

---

### 1-4. Dimension Error (CNN ì…ë ¥)

#### ë¬¸ì œ ìƒí™©

```python
conv = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=3)
inputs = torch.randn(28, 28)  # âŒ 2D í…ì„œ (H Ã— W)
out = conv(inputs)
# RuntimeError: Expected 4-dimensional input for 4-dimensional weight
```

#### CNN ì…ë ¥ ì°¨ì›

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CNN ì…ë ¥ ì°¨ì› ìš”êµ¬ì‚¬í•­                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚   ìš”êµ¬ í˜•ì‹: B Ã— C Ã— H Ã— W  (4D Tensor)                         â”‚
â”‚                                                                 â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚
â”‚   â”‚   B   â”‚    C    â”‚   H    â”‚   W    â”‚                        â”‚
â”‚   â”‚ Batch â”‚ Channel â”‚ Height â”‚ Width  â”‚                        â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
â”‚                                                                 â”‚
â”‚   ì˜ˆì‹œ: torch.randn(32, 3, 224, 224)                            â”‚
â”‚         â””â”€ 32ê°œ ë°°ì¹˜, 3ì±„ë„(RGB), 224Ã—224 ì´ë¯¸ì§€                â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### ì˜¬ë°”ë¥¸ ì½”ë“œ

```python
conv = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=3)

# âŒ 2D (H Ã— W)
inputs_2d = torch.randn(28, 28)

# âš ï¸ 3D (C Ã— H Ã— W) - ë°°ì¹˜ ì—†ì´ ë‹¨ì¼ ì´ë¯¸ì§€
inputs_3d = torch.randn(1, 28, 28)

# âœ… 4D (B Ã— C Ã— H Ã— W) - ê¶Œì¥
inputs_4d = torch.randn(1, 1, 28, 28)
out = conv(inputs_4d)
```

> ğŸ“š ê²€ìƒ‰ í‚¤ì›Œë“œ: `Expected 4-dimensional input`

---

## 2. Custom Model êµ¬í˜„ ì‹œ ì—ëŸ¬

### 2-1. Dimension Mismatch Error

#### ë¬¸ì œ ìƒí™©

Conv layer ì¶œë ¥ í¬ê¸°ì™€ FC layer ì…ë ¥ í¬ê¸°ê°€ ë¶ˆì¼ì¹˜

```python
class CNN(nn.Module):
    def __init__(self):
        super().__init__()
        self.layer = nn.Sequential(
            nn.Conv2d(1, 16, kernel_size=5),   # [1,28,28] â†’ [16,24,24]
            nn.ReLU(),
            nn.Conv2d(16, 32, kernel_size=5),  # [16,24,24] â†’ [32,20,20]
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2),       # [32,20,20] â†’ [32,10,10]
            nn.Conv2d(32, 64, kernel_size=5),  # [32,10,10] â†’ [64,6,6]
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2),       # [64,6,6] â†’ [64,3,3]
        )
        # âŒ ì˜ëª»ëœ ì…ë ¥ í¬ê¸°: 64*3*3 = 576ì¸ë° 1600ìœ¼ë¡œ ì„¤ì •
        self.fc_layer = nn.Linear(1600, 10)
```

#### ë””ë²„ê¹… ë°©ë²•

```python
# FC layer ì…ì¶œë ¥ í¬ê¸° í™•ì¸
for name, layer in model.named_modules():
    if isinstance(layer, nn.Linear):
        print(f"Layer {name}: {layer.in_features} -> {layer.out_features}")

# ë˜ëŠ” ì¤‘ê°„ ì¶œë ¥ í¬ê¸° ì§ì ‘ í™•ì¸
x = torch.randn(1, 1, 28, 28)
x = model.layer(x)
print(x.shape)  # torch.Size([1, 64, 3, 3])
print(x.view(x.size(0), -1).shape)  # torch.Size([1, 576])
```

#### ì˜¬ë°”ë¥¸ ì½”ë“œ

```python
# âœ… ì‹¤ì œ ì¶œë ¥ í¬ê¸°ì— ë§ê²Œ ìˆ˜ì •
self.fc_layer = nn.Linear(64 * 3 * 3, 10)  # 576 â†’ 10
```

> ğŸ“š ê²€ìƒ‰ í‚¤ì›Œë“œ: `mat1 and mat2 shapes cannot be multiplied`

---

### 2-2. Tensor Manipulation (view/reshape)

#### ë¬¸ì œ ìƒí™©

Global Average Pooling í›„ FC layer ì—°ê²° ì‹œ ì°¨ì› ë¶ˆì¼ì¹˜

```python
class Model(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv = nn.Conv2d(1, 10, kernel_size=5)
        self.gap = nn.AdaptiveAvgPool2d(1)  # 1Ã—1 GAP
        self.fc = nn.Linear(10, 10)

    def forward(self, x):
        x = self.conv(x)   # [B, 10, 24, 24]
        x = self.gap(x)    # [B, 10, 1, 1]
        # âŒ view ì—†ì´ ë°”ë¡œ FC ì—°ê²°
        x = self.fc(x)     # Error: 4D â†’ 2D ë³€í™˜ í•„ìš”
        return x
```

#### ì˜¬ë°”ë¥¸ ì½”ë“œ

```python
def forward(self, x):
    x = self.conv(x)           # [B, 10, 24, 24]
    x = self.gap(x)            # [B, 10, 1, 1]
    x = x.view(x.size(0), -1)  # âœ… [B, 10] - Flatten
    x = self.fc(x)             # [B, 10]
    return x
```

#### Flatten ë°©ë²•ë“¤

```python
# ë°©ë²• 1: view ì‚¬ìš©
x = x.view(x.size(0), -1)

# ë°©ë²• 2: reshape ì‚¬ìš©
x = x.reshape(x.size(0), -1)

# ë°©ë²• 3: flatten ì‚¬ìš©
x = x.flatten(start_dim=1)

# ë°©ë²• 4: nn.Flatten ë ˆì´ì–´ ì‚¬ìš©
self.flatten = nn.Flatten()
x = self.flatten(x)
```

---

## 3. í•™ìŠµ ë° í‰ê°€ ì‹œ ì—ëŸ¬

### 3-1. CUDA Out of Memory

#### ì—ëŸ¬ ë©”ì‹œì§€

```
RuntimeError: CUDA out of memory. Tried to allocate X MiB
```

#### GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ì²˜

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    GPU ë©”ëª¨ë¦¬ ì‚¬ìš© ìš”ì†Œ                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚   1. ë¯¸ë‹ˆë°°ì¹˜ ë°ì´í„°                                             â”‚
â”‚      â””â”€ batch_size Ã— input_shape                                â”‚
â”‚                                                                 â”‚
â”‚   2. ëª¨ë¸ íŒŒë¼ë¯¸í„°                                               â”‚
â”‚      â””â”€ ëª¨ë“  layerì˜ weight, bias                               â”‚
â”‚                                                                 â”‚
â”‚   3. ì—­ì „íŒŒìš© ì¤‘ê°„ ê²°ê³¼ë¬¼                                        â”‚
â”‚      â””â”€ ê° layerì˜ ì¶œë ¥ê°’ (gradient ê³„ì‚°ìš©)                     â”‚
â”‚                                                                 â”‚
â”‚   ğŸ’¡ ê°€ì¥ ì‰¬ìš´ í•´ê²°: batch_size ì¤„ì´ê¸°                           â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### í•´ê²° ë°©ë²•

**ë°©ë²• 1: batch_size ê°ì†Œ**
```python
# âŒ ë„ˆë¬´ í° ë°°ì¹˜
batch_size = 4096

# âœ… ì ì ˆí•œ í¬ê¸°ë¡œ ê°ì†Œ
batch_size = 256
```

**ë°©ë²• 2: torch.cuda.empty_cache()**
```python
# ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” í…ì„œ ì‚­ì œ
del large_tensor

# GPU ìºì‹œ ë¹„ìš°ê¸°
torch.cuda.empty_cache()
```

**ë°©ë²• 3: gradient accumulation**
```python
accumulation_steps = 4
optimizer.zero_grad()

for i, (inputs, labels) in enumerate(dataloader):
    outputs = model(inputs)
    loss = criterion(outputs, labels)
    loss = loss / accumulation_steps  # ì†ì‹¤ ìŠ¤ì¼€ì¼ë§
    loss.backward()
    
    if (i + 1) % accumulation_steps == 0:
        optimizer.step()
        optimizer.zero_grad()
```

**ë°©ë²• 4: mixed precision training**
```python
from torch.cuda.amp import autocast, GradScaler

scaler = GradScaler()

for inputs, labels in dataloader:
    optimizer.zero_grad()
    
    with autocast():  # FP16ìœ¼ë¡œ ì—°ì‚°
        outputs = model(inputs)
        loss = criterion(outputs, labels)
    
    scaler.scale(loss).backward()
    scaler.step(optimizer)
    scaler.update()
```

> ğŸ“š ê²€ìƒ‰ í‚¤ì›Œë“œ: `CUDA out of memory í•´ê²°`

---

### 3-2. detach(), cpu(), numpy() ë³€í™˜

#### ë¬¸ì œ ìƒí™©

```python
pred = torch.tensor([1., 0., 1.], requires_grad=True).to('cuda')
label = torch.tensor([1., 0., 0.]).to('cuda')

# âŒ ì—ëŸ¬ ë°œìƒ
pred_np = pred.numpy()
# RuntimeError: Can't call numpy() on Tensor that requires grad
```

#### ì˜¬ë°”ë¥¸ ë³€í™˜ ìˆœì„œ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Tensor â†’ NumPy ë³€í™˜ ìˆœì„œ                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚   CUDA Tensor (requires_grad=True)                              â”‚
â”‚         â”‚                                                       â”‚
â”‚         â–¼  .detach()  â”€â”€â”€ gradient ì—°ê²° í•´ì œ                    â”‚
â”‚         â”‚                                                       â”‚
â”‚   CUDA Tensor (requires_grad=False)                             â”‚
â”‚         â”‚                                                       â”‚
â”‚         â–¼  .cpu()  â”€â”€â”€ GPU â†’ CPU ì´ë™                           â”‚
â”‚         â”‚                                                       â”‚
â”‚   CPU Tensor                                                    â”‚
â”‚         â”‚                                                       â”‚
â”‚         â–¼  .numpy()  â”€â”€â”€ Tensor â†’ NumPy ë³€í™˜                    â”‚
â”‚         â”‚                                                       â”‚
â”‚   NumPy Array                                                   â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### ì˜¬ë°”ë¥¸ ì½”ë“œ

```python
pred = torch.tensor([1., 0., 1.], requires_grad=True).to('cuda')
label = torch.tensor([1., 0., 0.]).to('cuda')

# âœ… ì˜¬ë°”ë¥¸ ë³€í™˜ ìˆœì„œ
pred_np = pred.detach().cpu().numpy()
label_np = label.detach().cpu().numpy()

# sklearn ë“± numpy ê¸°ë°˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš© ê°€ëŠ¥
from sklearn.metrics import accuracy_score
accuracy_score(label_np, pred_np)
```

---

## 4. í”í•œ ì‹¤ìˆ˜ ì‚¬ë¡€

### 4-1. Random Seed ë¯¸ê³ ì •

#### ë¬¸ì œ

ì‹¤í—˜ ì¬í˜„ì´ ë¶ˆê°€ëŠ¥ â†’ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ê²°ê³¼ ì‹ ë¢° ë¶ˆê°€

#### í•´ê²°

```python
import random
import numpy as np
import torch
import torch.backends.cudnn as cudnn

def set_seed(seed):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    cudnn.benchmark = False
    cudnn.deterministic = True

# í•™ìŠµ ì‹œì‘ ì „ í˜¸ì¶œ
set_seed(42)
```

---

### 4-2. optimizer.zero_grad() ëˆ„ë½

#### ë¬¸ì œ

PyTorchëŠ” ê¸°ë³¸ì ìœ¼ë¡œ **gradientê°€ ëˆ„ì **ë¨

```python
# âŒ zero_grad ì—†ì´ í•™ìŠµ
for inputs, labels in dataloader:
    outputs = model(inputs)
    loss = criterion(outputs, labels)
    loss.backward()  # gradientê°€ ê³„ì† ëˆ„ì ë¨!
    optimizer.step()
```

#### í•´ê²°

```python
# âœ… ë§¤ ë°°ì¹˜ë§ˆë‹¤ gradient ì´ˆê¸°í™”
for inputs, labels in dataloader:
    optimizer.zero_grad()  # ğŸ”‘ í•„ìˆ˜!
    
    outputs = model(inputs)
    loss = criterion(outputs, labels)
    loss.backward()
    optimizer.step()
```

---

### 4-3. model.eval() ëˆ„ë½

#### ë¬¸ì œ

í‰ê°€ ì‹œ BatchNorm, Dropoutì´ í•™ìŠµ ëª¨ë“œë¡œ ë™ì‘

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              train() vs eval() ëª¨ë“œ ì°¨ì´                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚   Layer        â”‚  model.train()      â”‚  model.eval()           â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚   Dropout      â”‚  ëœë¤í•˜ê²Œ ë‰´ëŸ° ì œê±°  â”‚  ëª¨ë“  ë‰´ëŸ° ì‚¬ìš©         â”‚
â”‚   BatchNorm    â”‚  ë°°ì¹˜ í†µê³„ ì‚¬ìš©      â”‚  í•™ìŠµëœ í†µê³„ ì‚¬ìš©       â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Dropout ì˜ˆì‹œ

```python
dropout = nn.Dropout(0.5)
input_tensor = torch.randn(5, 10)

# Training Mode - 50% ë‰´ëŸ°ì´ 0ìœ¼ë¡œ ì„¤ì •ë¨
dropout.train()
output_train = dropout(input_tensor)
print(output_train)
# tensor([[-0.0000,  0.0800, -0.0000, ...]])  # 0ì´ ì„ì—¬ìˆìŒ

# Evaluation Mode - ëª¨ë“  ê°’ ìœ ì§€
dropout.eval()
output_eval = dropout(input_tensor)
print(output_eval)
# tensor([[-0.1234,  0.0400, -0.5678, ...]])  # 0 ì—†ìŒ
```

#### ì˜¬ë°”ë¥¸ í‰ê°€ ì½”ë“œ

```python
# âœ… í‰ê°€ ì‹œ ë°˜ë“œì‹œ eval() í˜¸ì¶œ
model.eval()

with torch.no_grad():  # gradient ê³„ì‚° ë¹„í™œì„±í™” (ë©”ëª¨ë¦¬ ì ˆì•½)
    for inputs, labels in test_dataloader:
        outputs = model(inputs)
        # í‰ê°€ ë¡œì§...

# ë‹¤ì‹œ í•™ìŠµí•  ë•ŒëŠ” train() í˜¸ì¶œ
model.train()
```

---

## ì—ëŸ¬ í•´ê²° ì²´í¬ë¦¬ìŠ¤íŠ¸

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PyTorch ì—ëŸ¬ ì²´í¬ë¦¬ìŠ¤íŠ¸                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  ğŸ“¦ Dataset ì—ëŸ¬                                                â”‚
â”‚  â–¡ __len__ì´ ì‹¤ì œ ë°ì´í„° ìˆ˜ë¥¼ ë°˜í™˜í•˜ëŠ”ê°€?                       â”‚
â”‚  â–¡ __getitem__ ì¸ë±ìŠ¤ê°€ ë²”ìœ„ ë‚´ì¸ê°€?                            â”‚
â”‚  â–¡ ë°ì´í„° íƒ€ì…ì´ ì˜¬ë°”ë¥¸ê°€? (Embeddingâ†’Long, Convâ†’Float)         â”‚
â”‚                                                                 â”‚
â”‚  ğŸ—ï¸ Model ì—ëŸ¬                                                  â”‚
â”‚  â–¡ Conv ì¶œë ¥ í¬ê¸°ì™€ FC ì…ë ¥ í¬ê¸°ê°€ ì¼ì¹˜í•˜ëŠ”ê°€?                  â”‚
â”‚  â–¡ Flatten/viewê°€ í•„ìš”í•œ ê³³ì— ìˆëŠ”ê°€?                           â”‚
â”‚  â–¡ ì…ë ¥ í…ì„œ ì°¨ì›ì´ ì˜¬ë°”ë¥¸ê°€? (CNN: 4D, RNN: 3D)                â”‚
â”‚                                                                 â”‚
â”‚  ğŸƒ Training ì—ëŸ¬                                               â”‚
â”‚  â–¡ optimizer.zero_grad()ë¥¼ í˜¸ì¶œí–ˆëŠ”ê°€?                          â”‚
â”‚  â–¡ GPU OOM ì‹œ batch_sizeë¥¼ ì¤„ì˜€ëŠ”ê°€?                            â”‚
â”‚  â–¡ Random seedë¥¼ ê³ ì •í–ˆëŠ”ê°€?                                    â”‚
â”‚                                                                 â”‚
â”‚  ğŸ“Š Evaluation ì—ëŸ¬                                             â”‚
â”‚  â–¡ model.eval()ì„ í˜¸ì¶œí–ˆëŠ”ê°€?                                   â”‚
â”‚  â–¡ torch.no_grad() ì»¨í…ìŠ¤íŠ¸ë¥¼ ì‚¬ìš©í–ˆëŠ”ê°€?                       â”‚
â”‚  â–¡ .detach().cpu().numpy() ìˆœì„œê°€ ì˜¬ë°”ë¥¸ê°€?                     â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Reference
- [PyTorch ê³µì‹ ë¬¸ì„œ](https://pytorch.org/docs/stable/index.html)
- [PyTorch íŠœí† ë¦¬ì–¼](https://pytorch.org/tutorials/)
- [CUDA Memory Management](https://pytorch.org/docs/stable/notes/cuda.html)
