# 개념정리

## 1. 인공지능 ⊃ 머신러닝 ⊃ 딥러닝
- 머신러닝: 함수공간에서 손실함수를 최적화하는 파라미터를 찾는 방식으로 구현
- 딥러닝: 심층신경망 구조의 모델을 사용하는 머신러닝의 일종

## 2. Loss와 학습
- Loss : 추측값 y hat과 목표값 y의 차이의 절대값
- 학습: 손실함수를 최소화하는 파라미터를 찾는것

## 3. 정형 vs 비정형
- 정형 데이터: 정량적 정보, 구조화 (테이블형태, 엑셀, csv)
- 비정형 데이터: 정성적 정보, 비구조화 (텍스트, 이미지, 음성)

## 4. NLP, CV, RecSystem
- NLP: 사람이 쓰는 언어, 문장, 단어를 ML 통해서 숫자로 표현해서 모델로 학습
- CV: 이미지, 동영상 데이터 다루는 ML 연구분야
- 비트맵: RGB의 강도를 0~255사이 정수로 나타내고 색상을 길이 3의 벡터로 표현하고 이미지 해상도(가로길이 x 세로길이)만큼 쌓아 이미지를 표현하는 방식
- 추천시스템: 개인관심사에 맞는 컨텐츠 제공. (유저의 피드백 정보, 구매기록, 웹페이지 방문기록)

## 5. EDA (선택적 데이터 탐색)
- Bias(편향), 라벨 노이즈 (결측,이상,중복), 모호한 데이터(명확한 기준 또는 폐기 필요)를 처리
- 기본정보 파악 -> 이상치,결측치 파악 -> Boxplot -> 변수별 통계량과 분포 확인 -> Correlation plot -> 데이터셋 전처리(이상치 결측치 처리) -> 피쳐 scale 조정(표준화, 정규화)
- 상관계수: 
  - 공선성(Colinearity): 한 변수가 다른 변수와 사실상 같은 값으로 표현
  - 다중선성(Multicolinearity): 한 변수가 평균값 등 다른 여러 변수의 조합으로 나타날때
    예) “수익”이라는 변수가 각각 달러, 원화라는 또다른 변수로 표현될때


## 6. ML 방법론

### 6-1. 지도학습: 정답을 직접 지정, 즉 사람이 라벨(y)를 설정, 함수의 출력값이 라벨(y)에 가까워지게 학습하는 방식
- 회귀모델 : 종속변수 y가 연속형
  - 선형회귀모델, 상관관계 분석
  - 로지스틱 회귀모델
- 분류모델 : 종속변수 y가 범주형/이산형 
  - KNN, Decision Tree, SVM

### 6.2. 비지도학습: 라벨 y를 활용하지 않고 x로만 모델을 학습하는 방식
- 차원축소 : PCA, t-SNE
- 군집화(Clustering) : k-Means 


## 7. 선형회귀
- 단순선형회귀모델
  - MSE 손실함수: 목표값과 출력값 간 차이의 제곱

- 상관관계 분석
  - 상관관계: 한 변수가 변화할 때 다른 변수도 함께 변화하는 경향성 보임
  - 인과관계: 한 변수의 변화가 원인이 되어 그 결과로 다른 변수를 변화시킬 때.
  - 4가지 가정 
    - 선형성: 두 변인 X와 Y의 관계가 직선적이어야
    - 등분산성: X의 값에 관계없이 Y의 분산이 일정해야
    - 정규성: 각 변인은 모두 정규분포를 따라야
    - 독립성: 각 샘플들은 모두 독립적이어야

- 상관계수: 상관관계의 강도
  - 공선성(Colinearity): 한 변수가 다른 변수와 사실상 같은 값으로 표현. (상관계수 1 or -1)
  - 다중공선성(Multicolinearity): 한 변수가 평균값 등 다른 여러 변수의 조합으로 나타날때. 
  - 예) “수익”이라는 변수가 각각 달러, 원화라는 또다른 단위로 표기되어 중복될 때


## 8. 분류

### 8-1. 선형모델 활용
1. 이진분류 : 결과값이 1일 확률을 예측
- 로지스틱 함수 : 인풋을 0, 1 사이로 변환해 확률로 해석될 수 있는 결과를 내는 함수
- 시그모이드 함수 (= 로지스틱 함수 in 딥러닝)
- 크로스엔트로피 (Binary CE) : 로지스틱 함수를 통과한, 모델의 출력값 확률에 대해 적용하도록 만들어진 손실함수. 
- 회귀모델에서 쓰던 MSE 대신, BCE를 사용하면 학습이 더 잘되는 이유:
  - 모델의 예측 결과가 완전히 틀린 경우, BCE는 매우 큰 패널티를 주지만 MSE는 그렇지 않음
  - 모델이 정답에 어느정도 근접한 결과를 내놓은 경우 MSE는 로스값이 너무 작아져 학습이 매우 느려짐
  - 로지스틱함수와 결합했을 때 미분식이 매우 간단해진다

2. 다중분류 : 결과값들의 합이 1 : [0.8, 0.2, 0.0]
- 원핫인코딩
- 소프트맥스: 결과 logit 벡터를 각각 클래스에 대한 확률을 나타내는 벡터로 변환해주는 함수
- 크로스엔트로피 (CE)

### 8-2. 기타방법
1. kNN (k-nearest neighbor) : 가장 근접한 k개 라벨을 기준으로 출력값을 결정
2. Decision tree : x 내의 대소 관계나 특정 임계값(threshold)와의 비교 등 판단을 계층적으로 적용
  - 불순도를 최소화 (손실함수와 같은 역할)하는 방향으로 기준값을 정함
  - 랜덤 포레스트 : 각 트리의 결과를 종합해 최종 출력값을 결정하는 방식. 앙상블
3. SVM : 두 클래스를 가장 잘 분리하는 결정 경계를 찾아내는 방법론. Margin값 (데이터포인트들~ 결정경게 사이 거리)을 최대화하도록 학습.
  - 커널 트릭 : 데이터를 고차원으로 변환해 선형분리가 가능하도록 만드는 기법 


