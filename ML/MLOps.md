# MLOps
ML Life cycle을 체계적으로 관리, 적절한 인프라에 의존(데이터 처리, 모델 트레이닝, 배포, 모니터링과 같은 핵심 작업 지원) 
## 1. 인프라 요소
1. Storage: 데이터 저장, 백업, 복구 기능 제공
- Amazon S3 대규모 데이터를 저장하고 접근하는 클라우드 기반 서비스, 대규모 이미지 데이터셋을 s3 버킷에 저장하여 ML모델 트레이닝에 활용.
2. Computing Resources: 
- Google Cloud의 Computing Engine에서 GPU를 활용해 모델 빠르게 트레이닝
3. 환경관리 툴
- 프로젝트별 독립적 환경 제공하는 패키지/환경관리시스템
- Conda 환경을 사용해 팀내 다양한 ML프로젝트 의존성 관리
4. Container
- 애플리케이션과 그 의존성을 패키지화하여 일관된 환경에서 실행할 수 있도록 지원
- Docker 컨테이너를 사용해 모델 트레이닝 환경을 일관되게 유지
5. Orchestrator
- 여러 컨테이너의 배포, 확장, 네트워킹 관리
- Kubernetes를 사용해 여러 모델 서빙 컨테이너를 자동으로 스케일링 및 관리
6. Workflow Management
- Apache Airflow를 사용해 일일 데이터 처리 및 모델 트레이닝 작업 자동화
7. CI/CD
- 모델 개발 및 테스트 주기 단축시켜 빠른 반복을 가능하게 하는 도구
8. 버전 관리
- 이전에 개발된 모델 재현을 위해 원하는 버전의 데이터, 코드를 활용
9. HTTP, REST API
- 다른 시스템과의 통신을 위한 표준 프로토콜 및 인터페이스
- 예: REST API call 요청을 해서 해당 모델 트레이닝 컨테이너를 실행










